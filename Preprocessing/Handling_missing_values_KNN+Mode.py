# -*- coding: utf-8 -*-
"""knn_mode_Myocardial_clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ze1ACfOHbvmPOjZeSRhHRrDyG2zp4H7I
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline
from pylab import *
import seaborn as sns
import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.impute import KNNImputer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_samples, silhouette_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
import statistics as st
from google.colab import files

file = files.upload()
df = pd.read_csv("Mi (2).csv")

a = df.columns
# numerical features
if [col for col in df.columns if len(df[col].unique()) > 10]:
   num_features = [col for col in df.columns if len(df[col].unique()) > 10]
num_features_df = df[num_features]

# categorical fetures
if [col for col in df.columns if len(df[col].unique())<=10]:
   cat_features = [col for col in df.columns if len(df[col].unique())<=10]
cat_features_df = df[cat_features]

cat_imputed_df = cat_features_df.copy()
for i, col in enumerate(cat_features):
        cat_imputed_df[col].fillna(value=st.mode(cat_imputed_df[col]), inplace=True)
cat_imputed_df

num_imputed_df = num_features_df.copy()
imputer = KNNImputer(n_neighbors=15, weights='uniform')

for i, col in enumerate(num_features):
  num_imputed_df[col] = pd.DataFrame(imputer.fit_transform(num_imputed_df[col].values.reshape(-1,1)))

# k.isna().sum()
num_imputed_df

imputed_df = pd.concat([num_imputed_df,cat_imputed_df],axis=1)

imputed_df.to_csv("imputed_df.csv",index = False)
num_imputed_df.to_csv("num_imputed_df.csv",index = False)
cat_imputed_df.to_csv("cat_imputed_df.csv",index = False)

df_orig = pd.DataFrame(imputed_df)

sc = StandardScaler()
scaled_df = sc.fit_transform(df_orig)

scaled_df
